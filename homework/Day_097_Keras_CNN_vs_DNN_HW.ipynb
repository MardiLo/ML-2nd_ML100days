{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.2"},"colab":{"name":"Day_097_Keras_CNN_vs_DNN_HW.ipynb","provenance":[],"collapsed_sections":[]},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"nOC23kddKBBm","colab_type":"code","colab":{}},"source":["import keras\n","from keras.datasets import cifar10\n","from keras.models import Sequential\n","from keras.layers import Dense, Flatten, Conv2D, MaxPooling2D\n","from keras.layers import Dropout\n","from keras.optimizers import RMSprop\n","import os"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"JZ75c4I_MLUJ","colab_type":"code","colab":{}},"source":["batch_size = 128 # batch 的大小，如果出現 OOM error，請降低這個值\n","num_classes = 10 # 類別的數量，Cifar 10 共有 10 個類別\n","epochs = 10 # 訓練的 epochs 數量"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"cGDIBUgVKBB-","colab_type":"text"},"source":["## DNN"]},{"cell_type":"code","metadata":{"id":"wMKyLeaRM1eD","colab_type":"code","colab":{}},"source":["# 讀取資料並檢視\n","(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n","print(f\"x_train shape: {x_train.shape}, {x_train.shape[0]} train samples\")\n","print(f\"x_test shape: {x_test.shape}, {x_test.shape[0]} test samples\")\n","\n","# 對 label 進行 one-hot encoding (y_trian 原本是純數字)\n","y_train = keras.utils.to_categorical(y_train, num_classes)\n","y_test = keras.utils.to_categorical(y_test, num_classes)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"9xxy13ymM4cn","colab_type":"text"},"source":["由於 DNN 只能輸入一維的資料，我們要先將影像進行攤平，若 (50000, 32, 32, 3) 的影像，攤平後會變成 (50000, 32 x 32 x 3) = (50000, 3072)"]},{"cell_type":"code","metadata":{"id":"yMYI-GMEKBB_","colab_type":"code","outputId":"e5e85f64-52c9-4bb3-b2c8-921da0a6d799","executionInfo":{"status":"ok","timestamp":1581742417433,"user_tz":-480,"elapsed":1142,"user":{"displayName":"Mardi Lo","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mBdUqAuSD0ep3065higfFCa-W0cfpE4NnOvpbTEcQ=s64","userId":"12619433578773875517"}},"colab":{"base_uri":"https://localhost:8080/","height":50}},"source":["# 將資料攤平成一維資料並且標準化\n","x_train = x_train.reshape(50000, 32*32*3).astype('float32') / 255.\n","x_test = x_test.reshape(10000, 32*32*3).astype('float32') / 255.\n","print(f\"x_train shape: {x_train.shape}, {x_train.shape[0]} train samples\")\n","print(f\"x_test shape: {x_test.shape}, {x_test.shape[0]} test samples\")"],"execution_count":0,"outputs":[{"output_type":"stream","text":["x_train shape: (50000, 3072), 50000 train samples\n","x_test shape: (10000, 3072), 10000 test samples\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"x1yFf-KIKBCJ","colab_type":"code","outputId":"83060983-e07f-4f99-b5dc-e3ae3e2bee0a","executionInfo":{"status":"ok","timestamp":1581742450370,"user_tz":-480,"elapsed":33436,"user":{"displayName":"Mardi Lo","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mBdUqAuSD0ep3065higfFCa-W0cfpE4NnOvpbTEcQ=s64","userId":"12619433578773875517"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["model = Sequential()\n","model.add(Dense(512, activation='relu', input_shape=(32*32*3,)))\n","model.add(Dropout(0.2))\n","model.add(Dense(512, activation='relu'))\n","model.add(Dropout(0.2))\n","model.add(Dense(num_classes, activation='softmax'))\n","\n","model.summary()\n","\n","model.compile(loss='categorical_crossentropy',\n","              optimizer=RMSprop(),\n","              metrics=['accuracy'])\n","\n","history = model.fit(x_train, y_train,\n","                    batch_size=batch_size,\n","                    epochs=epochs,\n","                    verbose=1,\n","                    validation_data=(x_test, y_test))\n","score = model.evaluate(x_test, y_test, verbose=0)\n","print('Test loss:', score[0])\n","print('Test accuracy:', score[1])"],"execution_count":0,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n","Model: \"sequential_1\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","dense_1 (Dense)              (None, 512)               1573376   \n","_________________________________________________________________\n","dropout_1 (Dropout)          (None, 512)               0         \n","_________________________________________________________________\n","dense_2 (Dense)              (None, 512)               262656    \n","_________________________________________________________________\n","dropout_2 (Dropout)          (None, 512)               0         \n","_________________________________________________________________\n","dense_3 (Dense)              (None, 10)                5130      \n","=================================================================\n","Total params: 1,841,162\n","Trainable params: 1,841,162\n","Non-trainable params: 0\n","_________________________________________________________________\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3576: The name tf.log is deprecated. Please use tf.math.log instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.where in 2.0, which has the same broadcast rule as np.where\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3005: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n","\n","Train on 50000 samples, validate on 10000 samples\n","Epoch 1/10\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n","\n","50000/50000 [==============================] - 12s 236us/step - loss: 2.2379 - acc: 0.2507 - val_loss: 1.9968 - val_acc: 0.2639\n","Epoch 2/10\n","50000/50000 [==============================] - 2s 45us/step - loss: 1.8567 - acc: 0.3303 - val_loss: 1.7448 - val_acc: 0.3685\n","Epoch 3/10\n","50000/50000 [==============================] - 2s 46us/step - loss: 1.7762 - acc: 0.3621 - val_loss: 1.6690 - val_acc: 0.4142\n","Epoch 4/10\n","50000/50000 [==============================] - 2s 49us/step - loss: 1.7250 - acc: 0.3793 - val_loss: 1.6709 - val_acc: 0.4183\n","Epoch 5/10\n","50000/50000 [==============================] - 2s 47us/step - loss: 1.6911 - acc: 0.3940 - val_loss: 1.6231 - val_acc: 0.4289\n","Epoch 6/10\n","50000/50000 [==============================] - 2s 46us/step - loss: 1.6578 - acc: 0.4069 - val_loss: 1.6570 - val_acc: 0.3998\n","Epoch 7/10\n","50000/50000 [==============================] - 2s 42us/step - loss: 1.6366 - acc: 0.4140 - val_loss: 1.5632 - val_acc: 0.4473\n","Epoch 8/10\n","50000/50000 [==============================] - 2s 43us/step - loss: 1.6208 - acc: 0.4228 - val_loss: 1.5645 - val_acc: 0.4394\n","Epoch 9/10\n","50000/50000 [==============================] - 2s 43us/step - loss: 1.6057 - acc: 0.4251 - val_loss: 1.5544 - val_acc: 0.4529\n","Epoch 10/10\n","50000/50000 [==============================] - 2s 45us/step - loss: 1.5865 - acc: 0.4329 - val_loss: 1.5894 - val_acc: 0.4215\n","Test loss: 1.5893558864593507\n","Test accuracy: 0.4215\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"qUYhnqu-KBCQ","colab_type":"text"},"source":["## CNN\n","CNN 的原理非常適合處理影像類的資料，就讓我們來看看，同樣的訓練條件，CNN 是否顯著優於 DNN 呢?"]},{"cell_type":"code","metadata":{"id":"rjUByHXjKBCS","colab_type":"code","outputId":"f4a2cc62-796c-433f-ce85-ce9d8ac06ab8","executionInfo":{"status":"ok","timestamp":1581742828538,"user_tz":-480,"elapsed":941,"user":{"displayName":"Mardi Lo","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mBdUqAuSD0ep3065higfFCa-W0cfpE4NnOvpbTEcQ=s64","userId":"12619433578773875517"}},"colab":{"base_uri":"https://localhost:8080/","height":50}},"source":["(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n","print(f\"x_train shape: {x_train.shape}, {x_train.shape[0]} train samples\")\n","print(f\"x_test shape: {x_test.shape}, {x_test.shape[0]} test samples\")\n","\n","# 將資料標準化\n","x_train = x_train.astype('float32') / 255.\n","x_test = x_test.astype('float32') / 255.\n","\n","# 對 label 進行 one-hot encoding (y_trian 原本是純數字)\n","y_train = keras.utils.to_categorical(y_train, num_classes)\n","y_test = keras.utils.to_categorical(y_test, num_classes)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["x_train shape: (50000, 32, 32, 3), 50000 train samples\n","x_test shape: (10000, 32, 32, 3), 10000 test samples\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"L-EvzlStKBCZ","colab_type":"code","outputId":"0882cdbe-cd2c-40b2-823e-0bf033d07018","executionInfo":{"status":"ok","timestamp":1581742893323,"user_tz":-480,"elapsed":65443,"user":{"displayName":"Mardi Lo","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mBdUqAuSD0ep3065higfFCa-W0cfpE4NnOvpbTEcQ=s64","userId":"12619433578773875517"}},"colab":{"base_uri":"https://localhost:8080/","height":966}},"source":["model = Sequential()\n","model.add(Conv2D(32, (3, 3), padding='same', activation='relu', input_shape=(32, 32, 3)))\n","model.add(Conv2D(32, (3, 3), activation='relu'))\n","model.add(MaxPooling2D(pool_size=(2, 2)))\n","model.add(Dropout(0.25))\n","\n","model.add(Conv2D(64, (3, 3), padding='same', activation='relu'))\n","model.add(Conv2D(64, (3, 3), activation='relu'))\n","model.add(MaxPooling2D(pool_size=(2, 2)))\n","model.add(Dropout(0.25))\n","\n","model.add(Flatten())\n","model.add(Dense(512, activation='relu'))\n","model.add(Dropout(0.5))\n","model.add(Dense(num_classes, activation='relu'))\n","\n","model.summary()\n","\n","model.compile(loss='categorical_crossentropy',\n","              optimizer=RMSprop(),\n","              metrics=['accuracy'])\n","\n","history = model.fit(x_train, y_train,\n","                    batch_size=batch_size,\n","                    epochs=epochs,\n","                    verbose=1,\n","                    validation_data=(x_test, y_test))\n","score = model.evaluate(x_test, y_test, verbose=0)\n","print('Test loss:', score[0])\n","print('Test accuracy:', score[1])"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Model: \"sequential_3\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","conv2d_5 (Conv2D)            (None, 32, 32, 32)        896       \n","_________________________________________________________________\n","conv2d_6 (Conv2D)            (None, 30, 30, 32)        9248      \n","_________________________________________________________________\n","max_pooling2d_3 (MaxPooling2 (None, 15, 15, 32)        0         \n","_________________________________________________________________\n","dropout_6 (Dropout)          (None, 15, 15, 32)        0         \n","_________________________________________________________________\n","conv2d_7 (Conv2D)            (None, 15, 15, 64)        18496     \n","_________________________________________________________________\n","conv2d_8 (Conv2D)            (None, 13, 13, 64)        36928     \n","_________________________________________________________________\n","max_pooling2d_4 (MaxPooling2 (None, 6, 6, 64)          0         \n","_________________________________________________________________\n","dropout_7 (Dropout)          (None, 6, 6, 64)          0         \n","_________________________________________________________________\n","flatten_2 (Flatten)          (None, 2304)              0         \n","_________________________________________________________________\n","dense_6 (Dense)              (None, 512)               1180160   \n","_________________________________________________________________\n","dropout_8 (Dropout)          (None, 512)               0         \n","_________________________________________________________________\n","dense_7 (Dense)              (None, 10)                5130      \n","_________________________________________________________________\n","activation_2 (Activation)    (None, 10)                0         \n","=================================================================\n","Total params: 1,250,858\n","Trainable params: 1,250,858\n","Non-trainable params: 0\n","_________________________________________________________________\n","Train on 50000 samples, validate on 10000 samples\n","Epoch 1/10\n","50000/50000 [==============================] - 12s 236us/step - loss: 1.7651 - acc: 0.3642 - val_loss: 1.3751 - val_acc: 0.5178\n","Epoch 2/10\n","50000/50000 [==============================] - 6s 114us/step - loss: 1.3024 - acc: 0.5372 - val_loss: 1.1936 - val_acc: 0.5695\n","Epoch 3/10\n","50000/50000 [==============================] - 6s 114us/step - loss: 1.1022 - acc: 0.6131 - val_loss: 0.9791 - val_acc: 0.6604\n","Epoch 4/10\n","50000/50000 [==============================] - 6s 114us/step - loss: 0.9700 - acc: 0.6611 - val_loss: 0.9800 - val_acc: 0.6573\n","Epoch 5/10\n","50000/50000 [==============================] - 6s 115us/step - loss: 0.8746 - acc: 0.6928 - val_loss: 0.8049 - val_acc: 0.7220\n","Epoch 6/10\n","50000/50000 [==============================] - 6s 115us/step - loss: 0.8004 - acc: 0.7222 - val_loss: 0.7595 - val_acc: 0.7401\n","Epoch 7/10\n","50000/50000 [==============================] - 6s 115us/step - loss: 0.7535 - acc: 0.7371 - val_loss: 0.7680 - val_acc: 0.7392\n","Epoch 8/10\n","50000/50000 [==============================] - 6s 113us/step - loss: 0.7118 - acc: 0.7503 - val_loss: 0.7024 - val_acc: 0.7650\n","Epoch 9/10\n","50000/50000 [==============================] - 6s 117us/step - loss: 0.6769 - acc: 0.7661 - val_loss: 0.7197 - val_acc: 0.7593\n","Epoch 10/10\n","50000/50000 [==============================] - 6s 115us/step - loss: 0.6534 - acc: 0.7742 - val_loss: 0.6824 - val_acc: 0.7693\n","Test loss: 0.682409874010086\n","Test accuracy: 0.7693\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"dpirkUZ1KBCh","colab_type":"text"},"source":["## 同樣運算 10 個 epochs，但 CNN 的準確率顯著優於 DNN!"]},{"cell_type":"markdown","metadata":{"id":"UJdyQL4FKBCj","colab_type":"text"},"source":["## 作業\n","1. 請試著調整各個超參數，並說明那些超參數對於結果有明顯的影響?\n","  \n","   Number of neurons, Dropout rate, Activation, Number of convolution kernels, Window size, Stride, Pooling, \n","\n","2. CNN 與 DNN 哪個模型的參數數量比較多? 造成參數的數量不同的原因在哪?\n","\n","   模型的設計使CNN可以更有效率的以更少的參數來訓練"]},{"cell_type":"code","metadata":{"id":"dxLSOL_nKBCl","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}